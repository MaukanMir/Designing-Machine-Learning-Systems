{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continual Learning and Test in Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spoiler: continual learning is largely an infrastructural problem. Then we’ll lay out a four-stage plan to make continual learning a reality.\n",
    "\n",
    "### First, if your model is a neural network, learning with every incoming sample makes it susceptible to catastrophic forgetting. Catastrophic forgetting refers to the tendency of a neural network to completely and abruptly forget previously learned information upon learning new information.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, if your model is a neural network, learning with every incoming sample makes it susceptible to catastrophic forgetting. Catastrophic forgetting refers to the tendency of a neural network to completely and abruptly forget previously learned information upon learning new information.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stateful training allows you to update your model with less data. Training a model from scratch tends to require a lot more data than fine-tuning the same model. For example, if you retrain your model from scratch, you might need to use all data from the last three months. However, if you fine-tune your model from yesterday’s checkpoint, you only need to use data from the last day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One beautiful property that is often overlooked is that with stateful training, it might be possible to avoid storing data altogether. In the traditional stateless retraining, a data sample might be reused during multiple training iterations of a model, which means that data needs to be stored. This isn’t always possible, especially for data with strict privacy requirements. In the stateful training paradigm, each model update is trained using only the fresh data, so a data sample is used only once for training, as shown in Figure 9-2. This means that it’s possible to train your model without having to store data in permanent storage, which helps eliminate many concerns about data privacy. However, this is overlooked because today’s let’s-keep-track-of-everything practice still makes many companies reluctant to throw away data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It can also happen when a user visits a service so infrequently that whatever historical data the service has about this user is outdated. For example, most people only book hotels and flights a few times a year. Coveo, a company that provides search engine and recommender systems to ecommerce websites, found that it is common for an ecommerce site to have more than 70% of their shoppers visit their site less than three times a year.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If your model doesn’t adapt quickly enough, it won’t be able to make recommendations relevant to these users until the next time the model is updated. By that time, these users might have already left the service because they don’t find anything relevant to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we could make our models adapt to each user within their visiting session, the models would be able to make accurate, relevant predictions to users even on their first visit. TikTok, for example, has successfully applied continual learning to adapt their recommender system to each user within minutes. You download the app and, after a few videos, TikTok’s algorithms are able to predict with high accuracy what you want to watch next.11 I don’t think everyone should try to build something as addictive as TikTok, but it’s proof that continual learning can unlock powerful predictive potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Stages of Continual Learning\n",
    "\n",
    "In the beginning, the ML team often focuses on developing ML models to solve as many business problems as possible. For example, if your company is an ecommerce website, you might develop four models in the following succession:\n",
    "\n",
    "- A model to detect fraudulent transactions\n",
    "\n",
    "- A model to recommend relevant products to users\n",
    "\n",
    "- A model to predict whether a seller is abusing a system\n",
    "\n",
    "- A model to predict how long it will take to ship an order\n",
    "\n",
    "### When creating scripts to automate the retraining process for your system, you need to take into account that different models in your system might require different retraining schedules. For example, consider a recommender system that consists of two models: one model to generate embeddings for all products, and another model to rank the relevance of each product given a query. The embedding model might need to be retrained a lot less frequently than the ranking model. Because products’ characteristics don’t change that often, you might be able to get away with retraining your embeddings once a week,24 whereas your ranking models might need to be retrained once a day.\n",
    "\n",
    "\n",
    "### Once you’re committed to stateful training, reconfiguring the updating script is straightforward. The main thing you need at this stage is a way to track your data and model lineage. Imagine you first upload model version 1.0. This model is updated with new data to create model version 1.1, and so on to create model 1.2. Then another model is uploaded and called model version 2.0. This model is updated with new data to create model version 2.1. After a while, you might have model version 3.32, model version 2.11, model version 1.64. You might want to know how these models evolve over time, which model was used as its base model, and which data was used to update it so that you can reproduce and debug it. As far as I know, no existing model store has this model lineage capacity, so you’ll likely have to build the solution in-house.\n",
    "\n",
    "\n",
    "Time-based\n",
    "- For example, every five minutes\n",
    "\n",
    "- Performance-based\n",
    "For example, whenever model performance plummets\n",
    "\n",
    "- Volume-based\n",
    "For example, whenever the total amount of labeled data increases by 5%\n",
    "\n",
    "- Drift-based\n",
    "For example, whenever a major data distribution shift is detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
